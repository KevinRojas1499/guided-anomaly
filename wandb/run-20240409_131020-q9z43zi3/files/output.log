Logging to /tmp/openai-2024-04-09-13-10-24-408894
Namespace(anneal_lr=True, batch_size=32, classifier_attention_resolutions='16,8', classifier_depth=2, classifier_pool='attention', classifier_resblock_updown=True, classifier_use_fp16=False, classifier_use_scale_shift_norm=True, classifier_width=128, data_dir='./Preprocessed/train', diffusion_steps=1000, eval_interval=5, image_size=128, iterations=100, learn_sigma=False, log_dir='./checkpoints', log_interval=10, lr=0.0003, microbatch=-1, noise_schedule='linear', noised=True, predict_xstart=False, rescale_learned_sigmas=False, rescale_timesteps=False, resume_checkpoint='', save_interval=100, schedule_sampler='uniform', timestep_respacing='', use_kl=False, val_data_dir='', weight_decay=0.05)
Namespace(anneal_lr=True, batch_size=32, classifier_attention_resolutions='32,16', classifier_depth=4, classifier_pool='attention', classifier_resblock_updown=True, classifier_use_fp16=False, classifier_use_scale_shift_norm=True, classifier_width=128, data_dir='./Preprocessed/train', diffusion_steps=1000, eval_interval=5, image_size=128, iterations=100, learn_sigma=False, log_dir='./checkpoints', log_interval=10, lr=0.0005069171045932743, microbatch=-1, noise_schedule='linear', noised=True, predict_xstart=False, rescale_learned_sigmas=False, rescale_timesteps=False, resume_checkpoint='', save_interval=100, schedule_sampler='uniform', timestep_respacing='', use_kl=False, val_data_dir='', weight_decay=0.01)
./checkpoints
Logging to ./checkpoints
creating model and diffusion...
creating data loader...
creating optimizer...
training classifier model...
-----------------------------
| grad_norm      | 166      |
| param_norm     | 175      |
| samples        | 32       |
| step           | 0        |
| train_acc@1    | 0        |
| train_acc@1_q0 | 0        |
| train_acc@1_q1 | 0        |
| train_acc@1_q2 | 0        |
| train_acc@1_q3 | 0        |
| train_acc@5    | 0.0312   |
| train_acc@5_q0 | 0        |
| train_acc@5_q1 | 0        |
| train_acc@5_q2 | 0        |
| train_acc@5_q3 | 0.143    |
| train_loss     | 6.64     |
| train_loss_q0  | 6.73     |
| train_loss_q1  | 6.63     |
| train_loss_q2  | 6.67     |
| train_loss_q3  | 6.54     |
-----------------------------
-----------------------------
| grad_norm      | 8.71     |
| param_norm     | 175      |
| samples        | 352      |
| step           | 10       |
| train_acc@1    | 0.247    |
| train_acc@1_q0 | 0.209    |
| train_acc@1_q1 | 0.348    |
| train_acc@1_q2 | 0.21     |
| train_acc@1_q3 | 0.2      |
| train_acc@5    | 1        |
| train_acc@5_q0 | 1        |
| train_acc@5_q1 | 1        |
| train_acc@5_q2 | 1        |
| train_acc@5_q3 | 1        |
| train_loss     | 2.67     |
| train_loss_q0  | 2.39     |
| train_loss_q1  | 2.87     |
| train_loss_q2  | 2.67     |
| train_loss_q3  | 2.65     |
-----------------------------
-----------------------------
| grad_norm      | 15.8     |
| param_norm     | 176      |
| samples        | 672      |
| step           | 20       |
| train_acc@1    | 0.231    |
| train_acc@1_q0 | 0.212    |
| train_acc@1_q1 | 0.269    |
| train_acc@1_q2 | 0.301    |
| train_acc@1_q3 | 0.135    |
| train_acc@5    | 1        |
| train_acc@5_q0 | 1        |
| train_acc@5_q1 | 1        |
| train_acc@5_q2 | 1        |
| train_acc@5_q3 | 1        |
| train_loss     | 1.54     |
| train_loss_q0  | 1.61     |
| train_loss_q1  | 1.48     |
| train_loss_q2  | 1.56     |
| train_loss_q3  | 1.5      |
-----------------------------
-----------------------------
| grad_norm      | 7.07     |
| param_norm     | 176      |
| samples        | 992      |
| step           | 30       |
| train_acc@1    | 0.237    |
| train_acc@1_q0 | 0.247    |
| train_acc@1_q1 | 0.233    |
| train_acc@1_q2 | 0.23     |
| train_acc@1_q3 | 0.241    |
| train_acc@5    | 1        |
| train_acc@5_q0 | 1        |
| train_acc@5_q1 | 1        |
| train_acc@5_q2 | 1        |
| train_acc@5_q3 | 1        |
| train_loss     | 1.45     |
| train_loss_q0  | 1.48     |
| train_loss_q1  | 1.44     |
| train_loss_q2  | 1.44     |
| train_loss_q3  | 1.44     |
-----------------------------
-----------------------------
| grad_norm      | 5.55     |
| param_norm     | 177      |
| samples        | 1.31e+03 |
| step           | 40       |
| train_acc@1    | 0.256    |
| train_acc@1_q0 | 0.264    |
| train_acc@1_q1 | 0.247    |
| train_acc@1_q2 | 0.259    |
| train_acc@1_q3 | 0.256    |
| train_acc@5    | 1        |
| train_acc@5_q0 | 1        |
| train_acc@5_q1 | 1        |
| train_acc@5_q2 | 1        |
| train_acc@5_q3 | 1        |
| train_loss     | 1.41     |
| train_loss_q0  | 1.41     |
| train_loss_q1  | 1.4      |
| train_loss_q2  | 1.38     |
| train_loss_q3  | 1.44     |
-----------------------------
-----------------------------
| grad_norm      | 6.45     |
| param_norm     | 177      |
| samples        | 1.63e+03 |
| step           | 50       |
| train_acc@1    | 0.241    |
| train_acc@1_q0 | 0.218    |
| train_acc@1_q1 | 0.239    |
| train_acc@1_q2 | 0.25     |
| train_acc@1_q3 | 0.256    |
| train_acc@5    | 1        |
| train_acc@5_q0 | 1        |
| train_acc@5_q1 | 1        |
| train_acc@5_q2 | 1        |
| train_acc@5_q3 | 1        |
| train_loss     | 1.44     |
| train_loss_q0  | 1.46     |
| train_loss_q1  | 1.44     |
| train_loss_q2  | 1.37     |
| train_loss_q3  | 1.47     |
-----------------------------
-----------------------------
| grad_norm      | 4.54     |
| param_norm     | 177      |
| samples        | 1.95e+03 |
| step           | 60       |
| train_acc@1    | 0.306    |
| train_acc@1_q0 | 0.411    |
| train_acc@1_q1 | 0.244    |
| train_acc@1_q2 | 0.247    |
| train_acc@1_q3 | 0.31     |
| train_acc@5    | 1        |
| train_acc@5_q0 | 1        |
| train_acc@5_q1 | 1        |
| train_acc@5_q2 | 1        |
| train_acc@5_q3 | 1        |
| train_loss     | 1.38     |
| train_loss_q0  | 1.37     |
| train_loss_q1  | 1.4      |
| train_loss_q2  | 1.39     |
| train_loss_q3  | 1.37     |
-----------------------------
-----------------------------
| grad_norm      | 5.27     |
| param_norm     | 177      |
| samples        | 2.27e+03 |
| step           | 70       |
| train_acc@1    | 0.228    |
| train_acc@1_q0 | 0.181    |
| train_acc@1_q1 | 0.306    |
| train_acc@1_q2 | 0.179    |
| train_acc@1_q3 | 0.25     |
| train_acc@5    | 1        |
| train_acc@5_q0 | 1        |
| train_acc@5_q1 | 1        |
| train_acc@5_q2 | 1        |
| train_acc@5_q3 | 1        |
| train_loss     | 1.41     |
| train_loss_q0  | 1.42     |
| train_loss_q1  | 1.38     |
| train_loss_q2  | 1.43     |
| train_loss_q3  | 1.4      |
-----------------------------
-----------------------------
| grad_norm      | 5.19     |
| param_norm     | 177      |
| samples        | 2.59e+03 |
| step           | 80       |
| train_acc@1    | 0.244    |
| train_acc@1_q0 | 0.253    |
| train_acc@1_q1 | 0.278    |
| train_acc@1_q2 | 0.188    |
| train_acc@1_q3 | 0.241    |
| train_acc@5    | 1        |
| train_acc@5_q0 | 1        |
| train_acc@5_q1 | 1        |
| train_acc@5_q2 | 1        |
| train_acc@5_q3 | 1        |
| train_loss     | 1.41     |
| train_loss_q0  | 1.41     |
| train_loss_q1  | 1.38     |
| train_loss_q2  | 1.44     |
| train_loss_q3  | 1.44     |
-----------------------------
-----------------------------
| grad_norm      | 5.87     |
| param_norm     | 177      |
| samples        | 2.91e+03 |
| step           | 90       |
| train_acc@1    | 0.256    |
| train_acc@1_q0 | 0.243    |
| train_acc@1_q1 | 0.293    |
| train_acc@1_q2 | 0.247    |
| train_acc@1_q3 | 0.234    |
| train_acc@5    | 1        |
| train_acc@5_q0 | 1        |
| train_acc@5_q1 | 1        |
| train_acc@5_q2 | 1        |
| train_acc@5_q3 | 1        |
| train_loss     | 1.4      |
| train_loss_q0  | 1.4      |
| train_loss_q1  | 1.4      |
| train_loss_q2  | 1.41     |
| train_loss_q3  | 1.4      |
-----------------------------
saving model...
Trying to save ./checkpoints
./checkpoints